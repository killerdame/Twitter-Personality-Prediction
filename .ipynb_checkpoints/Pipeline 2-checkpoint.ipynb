{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from scipy.stats import randint, uniform\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import sklearn.neural_network as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_df = pd.read_pickle('tweets_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twictionary = {'Elon Musk' : 0,\n",
    "               'Donald Trump' : 1,\n",
    "               'Ellen Degeneres' : 2,\n",
    "               'Kim Kardashian' : 3,\n",
    "               'Noam Chomsky' : 4,\n",
    "               'Michael Moore' : 5,\n",
    "               'Oprah Winfrey' : 6,\n",
    "               'Katy Perry' : 7,\n",
    "               'Paulo Coelho' : 8,\n",
    "               'Gina Rodriguez' : 9,\n",
    "               'Russell Brand' : 10,\n",
    "               'Barack Obama' : 11}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Using Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_data = pd.read_pickle('cleaned_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfid_vec = TfidfVectorizer(stop_words='english', decode_error='replace', use_idf=True, max_df=2.0)\n",
    "c_tfid = tfid_vec.fit_transform(cleaned_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_svd = TruncatedSVD(n_components=500, n_iter=100)\n",
    "c_transformed_X = pd.DataFrame(c_svd.fit_transform(c_tfid))\n",
    "#about 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAF9CAYAAAA5hAOVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzOrGwciZmZmVjcORMzMzKxu/gfoGtw4X53dgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1127b9290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(500)\n",
    "plt.plot(x, np.cumsum(c_svd.explained_variance_ratio_), color='black')\n",
    "plt.ylim(0, 0.5)\n",
    "\n",
    "plt.xlabel('Cleaned SVD components')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfid_vec = TfidfVectorizer(stop_words='english', decode_error='replace', use_idf=True, max_df=2.0)\n",
    "tfid = tfid_vec.fit_transform(tweets_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=500, n_iter=100)\n",
    "transformed_X = pd.DataFrame(svd.fit_transform(tfid))\n",
    "#about 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAF9CAYAAAA5hAOVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3Xl8VNX5x/FPFvZFKcgiqCjCwxb2VUDBfV+wLpW6Yaut\n2tpqba3W5Wdb21q1VutSa92tVuuO4oqKbLIJsuUJqLgbRNkJS5L5/XFv4hASSIaZuUnm+3698krm\n3HtnHo7j5Jtz7z0nKxaLISIiIhKF7KgLEBERkcylICIiIiKRURARERGRyCiIiIiISGQURERERCQy\nCiIiIiISGQURERERiYyCiIiIiERGQUREREQikxt1AQBm1gi4ExgLbARudvdbqtj3OeA4IAZkhd+P\nc/eX0lSuiIiIJEmtCCLATcAAYDTQGXjIzJa7+9OV7NsDOAOYFNe2KtUFioiISPJlRb3WjJk1BVYC\nR7j7O2HbVcAh7n5whX0bAhuAHu6+LO3FioiISFLVhmtE+hKMzEyPa5sCDK1kXwNKgQ/TUJeIiIik\nWG0IIh2Ale5eHNdWCDQ2s9YV9u0BrAUeMbMvzOxdMzsyXYWKiIhIctWGINIU2Fyhrexxowrt3YEm\nwETgCOAl4AUzG5DSCkVERCQlasPFqpvYPnCUPd4Y3+ju15vZ3919Tdi0wMwGAucDP6nOi8VisVhW\nVtau1CsiIpKpkv4LtDYEkc+BNmaW7e6lYVt7oMjdV1fcOS6ElFkC9Kzui2VlZbF2bRElJaU731l2\nWU5ONi1bNlGfp5H6PP3U5+mnPk+/sj5PttoQROYBW4FhwLSwbRQwq+KOZnY/UOru58U19wPer8kL\nlpSUUlysN246qc/TT32efurz9FOf132RBxF3LzKzh4C7zWw80Am4DDgbwMzaAWvcfRPwPPCYmb1F\nEFrGASOAH0dRu4iIiOya2nCxKsClwByCScpuB6529+fCbV8CpwK4+zPAhcDvgAUEM6we4e6fpL1i\nERER2WWRT2gWgdiqVRs0lJcmubnZtGrVDPV5+qjP0099nn7q8/QL+zzpF6vWlhERERERyUAKIiIi\nIhIZBRERERGJjIKIiIiIREZBRERERCKjICIiIiKRURARERGRyCiIiIiISGQURERERCQyCiIiIiIS\nGQURERERiYyCiIiIiERGQUREREQioyAiIiIikVEQERERkcgoiIiIiEhkFEREREQkMgoiIiIiEhkF\nEREREYmMgoiIiIhERkFEREREIqMgIiIiIpFREBEREZHIKIiIiIhIZBREREREJDIKIiIiIhIZBRER\nERGJjIKIiIiIREZBRERERCKjICIiIiKRURARERGRyCiIiIiISGQURERERCQyCiIiIiISGQURERER\niYyCiIiIiERGQUREREQioyAiIiIikVEQERERkcgoiIiIiEhkFEREREQkMgoiIiIiEhkFEREREYmM\ngoiIiIhERkFEREREIqMgIiIiIpFREBEREZHIKIiIiIhIZBREREREJDIKIiIiIhKZ3KgLADCzRsCd\nwFhgI3Czu9+yk2M6AwuAY9x9csqLFBERkaSrLSMiNwEDgNHAhcC1ZjZ2J8fcBTRNcV0iIiKSQpEH\nETNrCpwH/Nzd57v7c8CNwMU7OGYc0DxNJYqIiEiKRB5EgL4Ep4imx7VNAYZWtrOZtQb+DJwPZKW8\nOhEREUmZ2hBEOgAr3b04rq0QaByGjopuAR5w9yVpqU5ERERSpjZcrNoU2Fyhrexxo/hGMzsUOAD4\n8a68YE5ObchfmaGsr9Xn6aM+Tz/1efqpz9MvVX1dG4LIJioEjrjHG8sazKwxcDfwU3ffsisv2LJl\nk105XBKgPk8/9Xn6qc/TT31e99WGIPI50MbMst29NGxrDxS5++q4/YYA+wJPmVn8tSETzexBd7+w\nui+4dm0RJSWlO99RdllOTjYtWzZRn6eR+jz91Ofppz5Pv7I+T7baEETmAVuBYcC0sG0UMKvCfu8C\nXSu0LSO44+b1mrxgSUkpxcV646aT+jz91Ofppz5PP/V53Rd5EHH3IjN7CLjbzMYDnYDLgLMBzKwd\nsMbdNwEfxh9rZgBfuPvK9FYtIiIiyVBbrvK5FJgDTAJuB64O5xMB+BI4tYrjYmmoTURERFIkKxbL\nuN/lsVWrNmgoL01yc7Np1aoZ6vP0UZ+nn/o8/dTn6Rf2edLn76otIyIiIiKSgRREREREJDIKIiIi\nIhIZBRERERGJjIKIiIiIREZBRERERCKjICIiIiKRURARERGRyCiIiIiISGQURERERCQyCiIiIiIS\nGQURERERiYyCiIiIiERGQUREREQioyAiIiIikVEQERERkcgoiIiIiEhkFEREREQkMgoiIiIiEhkF\nEREREYmMgoiIiIhERkFEREREIqMgIiIiIpFREBEREZHI5CZykJkdBlwOdAdGAWcBS9398STWJiIi\nIvVcjUdEzOwQYAKwAmgL5ADNgEfMbFxyyxMREZH6LJFTM9cDv3X3HwJbAdz9CuBq4NdJrE1ERETq\nuUSCSB/guUraHwe67lo5IiIikkkSCSJrgQ6VtPcEVu1aOSIiIpJJEgki/wH+ZmY9gRjQxMwOBW4H\nnkhmcSIiIlK/JRJErgI+AhYCzYH3gVeB/HCbiIiISLXU+PZdd98CnGpm3YABBGFmobu/n+ziRERE\npH6rcRAxsyzgt8AKd783bJtiZs+7+43JLlBERETqr0ROzVwHXMa2F6Y+A/zazH6TjKJEREQkMyQS\nRM4BznD3p8oa3P3msP2C5JQlIiIimSCRINIG+LCS9nwqv61XREREpFKJBJH3gbMraT8DWLxr5YiI\niEgmSWTRu+uBCWY2EpgRtg0GDgROSlZhIiIiUv/VeETE3ScCBxEsencCcDTwNTDU3ScktzwRERGp\nzxIZEcHdpwBTklyLiIiIZJiEgoiZDQNGAA2BrPht7n5DEuoSERGRDJDIhGZXAn8A1hEsgBcvBiiI\niIiISLUkMiJyEXCNu/8h2cWIiIhIZknk9t1WwMPJLkREREQyTyJBZDowPNmFiIiISOZJ5NTMQ8A/\nzKw/wWyqm+M3uvt/klGYiIiI1H+JBJH7w++XV7ItBiiIiIiISLUkEkQaJL0KERERyUg1DiLuXlLV\nNjPrAHy5SxWJiIhIxkhkHpHOwI1AHpATNmcBjQhW39WIiYiIiFRLIqdm7gB6AE8BvwBuAboDxwE/\nTaQIM2sE3AmMBTYCN7v7LVXsOw64BtgLmAv80t1nJfK6IiIiEq1Ebt8dCZzn7pcDi4D/ufsJwJ+B\nIxKs4yZgADAauBC41szGVtwpXPH3XuA6oCfBrcQTzaxpgq8rIiIiEUokiDQGloU/O9An/PlBYFhN\nnywMEecBP3f3+e7+HMGpn4sr2b09cL27P+buy4Hrge8RhBIRERGpYxI5NbOc4Bf/pwRBpF/YngW0\nTOD5+oZ1TI9rmwJcWXFHd/9f2c9m1hi4FCgEFifwuiIiIhKxRCc0e9jMzgJeBN4wsw8JTsu8n8Dz\ndQBWuntxXFsh0NjMWrv7NxUPMLODgVfDh+PcfWMCrysiIiIRSySI3EAwm2oDd3/XzP5MsBrvp8C4\nBJ6vKRVmZ4173KiKYxYQXFNyLPCgmX3k7jOr+4I5OYmckZJElPW1+jx91Ofppz5PP/V5+qWqr7Ni\nsVhKnri6zOz7wG3uvmdcW3eCC2Fbu/vqnRz/AvC1u4+v5ktG+w8WERGpu7KS/YTVGhExsyuBv7l7\nUfhzldz9hhrW8DnQxsyy3b00bGsPFFUMIWY2CChx9/fimhcT3E5cbWvXFlFSUrrzHWWX5eRk07Jl\nE/V5GqnP0099nn7q8/Qr6/Nkq+6pmZ8C/wSK2PFcITGCUzc1MQ/YSnDHzbSwbRRQ2dwg5wH7AkfG\ntQ0E5tTkBUtKSiku1hs3ndTn6ac+Tz/1efqpz+u+agURd98r7uGo8NbZpAhHWR4C7jaz8UAn4DLg\nbAAzawescfdNwD3ADDP7GTAROBMYHH4XERGROiaRK0+mmtmQJNdxKcGoxiTgduDqcD4RCNauORUg\nPCVzEvAjYD7ByMjh7q71bUREROqgRO6aKQa2JLMIdy8Czg2/Km7LrvD4JeClZL6+iIiIRCORIHIf\nwbTqDxDMsFoUv9Hd/5OEukRERCQDJBJErg2//6aSbTFAQURERESqJZEg0iDpVYiIiEhGqnEQcfeS\nqraZWQeCi0tFREREdqrGQcTMOhOsjpsH5ITNWQTTsXdAIyYiIiJSTYncvnsHMAiYQDC52DMEs5t2\nAi5OXmkiIiJS3yUSREYC57n75QTrwfzP3U8A/kywAq+IiIhItSQSRBoT3LYL4ECf8OcHCaZpFxER\nEamWRILIcqBn+LMD/cKfs4CWSahJREREMkQit+8+BDxsZmcBLwJvmNmHBKdl3k9mcSIiIlK/JRJE\nbgA2Aw3c/V0z+zPwB+BT4IxkFiciIiL1W1YsFtvpTmY2zN1npKGedIitWrVBy0anSW5uNq1aNUN9\nnj7q8/RTn6ef+jz9wj7PSvrzVnO/aWa2GLgXeNjdv0l2ISIiIpJ5qnux6ihgGnAN8LmZPWFmh6eu\nLBEREckE1Qoi7j7V3c8nmDn1bKAp8KKZfWxm15nZPqksUkREROqnGt2+6+6b3f2/7n4s0BH4O3Ai\n8IGZvWpmp6aiSBEREamfEplHBAB3X+Hut7h7P2AosDvwWNIqExERkXovkdt3ATCzXOAoYBxwLLAa\n+FOS6hIREZEMkMjquyMJwscpQAvgBeBU4GV31z1UIiIiUm3VCiJm1osgfPwA2Jtgtd0/EtzKuzJ1\n5YmIiEh9Vt0RkQXAWuC/wL/dfWbqShIREZFMUd0gcg7wpLsXpbAWERERyTDVCiLu/lCqCxEREZHM\nk/BdMyIiIlI/xWIxVqwopKDAKShwli512rVrxw03/D7pr6UgIiIikqFKS0v57LNPKSjIp6CgIPzu\nLF1awJo1q7fbX0FEREREamzr1q189NGH5aMb7vksXVrABx8sZePGjTs9vmPHTowefXBKalMQERER\nqSeKiopYtmwpBQX5YeAIgseHH35AcXHxDo/Nzs6mc+d96dbN6NatO127dqNbN6Nr1240b96C3NyE\nJ2PfoerOI1IKxKqzr7vn7FJFIiIiskNr164pv37ju1EO59NPPyYW2/Gv64YNG9KlS9cwcFgYNowu\nXfanUaNGafoXfKe6IyLj+S6I7ANcAfwTmAZsBQYDFwF/SHaBIiIimWr16lXk5+fjviT8cgoK8iks\n/GqnxzZr1pxu3brRtWswwlEWOvbZpzM5ObVnzKC6t+8+UPazmb0NXOzu98Xt8qyZLQZ+AdyU1ApF\nRETqubVr1+CeH34tIT9/Ce75fPXVlzs9tnXr1nTtGoxqmFkYPIw99+xIVlZWGqrfNYlcIzIEOK+S\n9plAr10rR0REpP5av349BQX55OeXhY0gcHzxxec7PbZ9+w5069Yds+9GOLp2Ndq0aZOGylMnkSCy\nFDid7U/DnA8s2uWKRERE6rgNGzawdKmXj2yUBY5PP/1kp8fusUdbunfvgVl3zHpg1oPu3buz++6t\n0lB5+iUSRK4F/mdmhwGzgGzgAKAfcFQSaxMREanVgrtUCsoDR37+YvLz86t10Wjr1q3DoBEEjh49\nemLWne99r3Waqq8dahxE3P0ZMxsF/Aw4guAi1nnABe4+P8n1iYiIRG7r1q188MEylixZRH7+YpYs\nCU6rfPzxckpLS3d47O67714+stGjR4/yn/fYY480VV+7JTSPiLtPI7hjRkREpN6IxWJ88cXnLFmy\niMWLF7NkySKWLFnMsmUFbNmyZYfHtmjRErPu5SMbwSmVHrRt265OXDQalYSCiJkdBVwOdAeGA+cC\ny9z9kSTWJiIikjJr165hyZIlYdhYxOLFi8jPX1Lp1ObxmjZtRvfu3enevWf5qZXu3XvQocOeChwJ\nqHEQCa8NeQZ4nCCE5AANgAfMLFsr9YqISG2yZcsWli1bWj66Ufb9s88+3eFxOTk5dOmyPz169KJH\nj57l3/feex+ys1Mzy2gmSmRE5P+AK9z9VjM7GcDdrzKzNQSjJAoiIiKSdrFYjM8++3S7wLF0acFO\npzfv0GHPbcJGjx696NbNIplpNNMkEkTygDMraX8SuG6XqhEREamG9evXs2TJfKZPn8mCBQtZvHgh\n+flLWLdu7Q6Pa9GiJd279ygPHD17Bt/r662xdUEiQWQNsCfwQYX2XsC3u1yRiIhIqGyUY9GihSxa\ntKD8+0cffbjD4xo0aMD++3ejR48e24xydOq0l67jqGUSCSKPArea2bkEt+42N7MjgX8A/01mcSIi\nkjmKiopwX7JN6Fi8eNFOLx7t2LFTOLJRNsrRmy5d9qdhw4Zpqlx2RSJB5HfAXgRzhwC8B2QBE4Cr\nklSXiIjUU7FYjMLCr7YZ4Vi0aCHLli3d4ZwcjRo1wqwHvXr1Ji8vj+HDh7D33l1o0WL3NFYvyZbI\nhGZbgTPM7BqC2VSzgYXuvjjZxYmISN22ZcsWCgo8LnQsZPHiBXzzzTc7PK5t23b06tWbXr3yyr/v\nv39XcnODX1u5udm0atWMVas2UFy84wnFpHZLaB6R0DrgXYLREMxsbwB33/lE+iIiUu+sXbuGhQsX\nsGDBfBYseJ+FCxewdKmzdevWKo/Jzc2la9du9OwZhI3evfPo1StPs45mkETmETkAeADoUmFTFsE1\nIzm7XpaIiNRmhYWFLFwYBI7gaz7Ll3+0w2NatWq1zQhHr1696datu26RzXCJjIjcBnwJ/IrgDhoR\nEamnYrEYn3zyMe+/P3+b4FFY+NUOj9tvvy707t0nHOEIgodmHpXKJBJEegP93X1JsosREZHoFBcX\ns2zZUhYsmB8Gj+D0yo7uWsnNzcWsB3369CUvrw+9e/eld+/eNG/eIo2VS12WSBD5FGie7EJERCR9\nNm3axJIli1iw4P3y0Y7FixexadOmKo9p2rQpvXrlkZfXh7y8IHiY9dCpFdkliQSRPwB/N7MLgPzw\nLhoREaml1q9fz8KFC5g/f2759RwFBU5JSUmVx7Rq1Yq8vH5h6AiCx377dSEnR5cBSnIlOo/I3oTz\niJjZNhvdXe9SEZGIbNiwoTx0zJ8/j/nz32Pp0gJisViVx3Ts2Ck8rfLdSEfHjp10PYekRaIjIkll\nZo2AO4GxwEbgZne/pYp9jwlr2J9gmvmr3f2FZNckIlLbbdy4sdLQUdWkYFlZWey3Xxf69OlL7959\ny0c6WrdunebKRb6TyIRmD6agjpuAAcBooDPwkJktd/en43cysz7AU8BlwETgSOB/ZjbI3RekoC4R\nkVph48aNLFq0gPnz3ysPHQUFvsOZSLt02Z++ffvTt29/+vXrT15eH11EKrVOtYKImd0HXOLu68Kf\nqxJz9/NqUoCZNQXOA45w9/nAfDO7EbgYeLrC7j8A3nD3O8LHd5rZ8cCpgIKIiNQLRUVF24UO9/wd\nho799utCv3796dPnu9DRokXLNFYtkpjqjojsy3cTle2b5Br6hnVMj2ubAlxZyb4PAJWtYrRbkmsS\nEUmLzZs3s3jxQt57by7z57/HvHnvUVCQv8MLSffddz/69u1H374D6Nu3H3369KVlS30MSt1UrSDi\n7mMq+zlJOgAr3b04rq0QaGxmrd29fEECd/f4A82sF3AIwfUlIiK1WmlpKR98sIy5c2fz3ntzmDdv\nLgsXLmDLli1VHtO5877lp1fKQsduu2mRN6k/ElprxsxygXZ8N0qSBTQCBrv7ozV8uqbA5gptZY+r\nvDndzNoQXC/yjrs/X5MXzMnJrlGBkriyvlafp4/6PP2q6vMvvviCuXNnM3fuHN57bw5z585l3bq1\nVT7PPvt0pl+//uVfffv2Y/fdW6W09rpK7/P0S1VfJ7LWzOHAQ0BlKxIVATUNIpvYPnCUPd5YRQ3t\ngNcI1rY5pYavR8uWTWp6iOwi9Xn6qc/Ta/Xq1cyePZuZM2cya9YsZs6cyRdffFHl/m3btmXIkCEM\nGTKEwYMHM3jwYN29kgC9z+u+REZEbgDmEqw58yQwDtgHuB44N4Hn+xxoY2bZ7l52JVZ7oMjdt5tX\n2Mw6ApOAEmB0/Kmb6lq7toiSEi0bnQ45Odm0bNlEfZ5G6vPU27RpEwsXLogb7ZjL0qUFVe7frFkz\n+vXrz4ABgxgwYCADBgykU6e9tpunY9WqDakuvd7Q+zz9yvo82RIJIr2A8e7+vpnNAza4++1mtp5g\nIbxna/h884CtwDBgWtg2CphVccfwDpuXw/3HuPvXCdRPSUkpxcV646aT+jz91OfJEYvF+PDDZcye\nPYs5c2Yxb95cFi1aWOXS9rm5ufTs2Zv+/YPA0b//QLp27bbdjKQlJTGCQV3ZFXqf132JBJESvlt1\ndxnBInhvEIxS3FzTJ3P3IjN7CLjbzMYDnQjmCTkbyk/DrHH3TcBVBHftjAayw20QjJ5UfeJVRKSa\n1q1by9y5c5g9eyZz5gThY9WqVVXu36XL/gwYMJCRIw+ge/c8evToTePGjdNYsUjdlkgQWQgcD9wO\nLAFGAn8nCBCJupTgzpdJBCHnand/Ltz2JXAOwXUpY4EmwLsVjn8QGL8Lry8iGai0tJSlSwu2CR35\n+UuqnA59jz3aMnDgYPr3H0D//gPp168/u+/eitzcbFq1asaqVRv017lIDWXtaP2BypjZicD/gIuA\nl4ACggDRB5jh7jW+eDTNYvqwSB99QKef+rxqq1Z9y9y5s5k9exazZ89k7tw5Vd7F0qBBA/r06cvA\ngYMZOHAwgwYNqfS6DlCfR0F9nn5hnyd9AaJEpnh/1syGACXu/qmZHUkwovEccE2yCxQRSURJSQlL\nlixmzpxZ5SMey5YtrXL/jh07xYWOweTl9dUpFpE0SGgeEXefG/fz28DbSatIRCQBq1evYvbsmcyc\n+W75aMfGjZXfhdKoUSP69u1fPtIxaNBgOnTYM80ViwjUbK2ZanF3XashIikVi8VYvvwjZs6cwcyZ\n7zJr1gzy85dUuf/ee3dm0KBBDBo0hIEDB9OrVx4NG1a2WoSIpFtN1poREYnEli1bWLBgPjNnvhuG\njxl8/fWKSvdt0qQJ/fsPLA8dAwcOpm3btmmuWESqq8ZrzYiIpNrq1auYNevd8uAxb95cioqKKt23\nbdt2DBkyjCFDhjJkyDDy8vrSoEGDNFcsIolKdK2ZFsDpQB7BvCJzgP+Fc32IiFRbLBbjo48+ZObM\nGWH4mIF7fqX7ZmVl0b17DwYP/i547LNP50rvZBGRuiGRtWa6A28CLQAnWPjufOAaMzvY3T9Lboki\nUp+UlpayePEiZsyYyowZ05k+fWqVp1maNm3KgAGDykPHwIGDtfKsSD2TyIjI7cB7wDh3XwXlK+E+\nRrD+zNjklScidd3WrVt5//15TJ8+jRkzpvLuuzNYs2a7ZaQAaN++wzanWXr1ytNpFpF6LpEgMhwY\nWhZCANx9pZn9CngnaZWJSJ1UVFTE3LmzmT59KtOnT2POnJls3FjpQtqYdWfYsBEMHTqMIUOGsdde\ne+s0i0iGSSSIfEUwnfuiCu0tgW93uSIRqVPWrVvLrFnvMn36NKZPn8p7782pdEG47Oxsevfuw/Dh\nB4ThYzht2rSJoGIRqU0SCSKXA3ea2WXAWwQr4Q4mWCvmVjPbu2xHd/8kGUWKSO3x7bfflJ9mmT59\nGgsXvk9p6fZTbDdo0ID+/QcyfPgIhg0bzuDBQ2nZcrcIKhaR2iyRIPJU+P1ptl3DOgu4hWAF3qxw\n27brXotInbN69SqmTZvKtGnvMGXKOyxevLDS/Zo0acKgQUMZPvwAhg8fwYABg2jSpEmaqxWRuiaR\nIKI5RUTqsbVr1zBjxjSmTHmHqVPfYeHC9ytdjbZly90YOnQYw4aNYPjwA+jTp59mKxWRGkskiCx3\n948r22BmR7n7xF2sSUTSaP36dcycOSMMHpOZP39epadaWrbcjeHDD2DEiFGMGHEgPXv2IidHg54i\nsmsSCSLzzOwCd3+irMHMmgB/A36MTseI1GobN25k5swZTJ36DlOmTGbevLmUlJRst1/z5i0YNmw4\nI0YcyMiRo+jdu4+Ch4gkXSJB5C7gP2Z2OPAzoA/wMMEEZ6cmsTYRSYLi4mLmzZvL5MlvMXnyW8ya\n9W6ld7U0bdqMoUOHhSMeo+jbtz+5uQlNviwiUm01/pRx9yvN7CXgISAf6AD8B/hl/NwiIhKNWCyG\nu/P88y/y5ptvMnXqO6xdu2a7/Ro3bszgwcMYOTI41dK//wBNHiYiaZfonzufAx8BIwnukPkIWJes\nokSkZlasWME777xVPurx+efbr7SQk5PDwIGDOfDA0YwadRADBgyiUaNGEVQrIvKdRNaa+SVwPbCY\nYNG7PsDdwIlmNt7d30tuiSJS0YYNG3j33Wm89dabTJ78VpW31Jp156CDxnDggaMZPnwELVq0THOl\nIiI7lsiIyI3ADcD17l4CFJjZVOA+4F1A9++JJFksFmPhwgW8+ebrTJr0epXXebRr157Ro8dwzDFH\nMXDgcPbYo10E1YqIVF8iQWSEu8+Mb3D3L4GjzOzC5JQlIqtWfcvbb7/JpElB+FixonC7fZo1a86I\nESM58MDRHHTQwXTrZjRokEOrVs1YtWoDxcXb34YrIlKbVCuImNn33P1bgIohJG6fhgTr0IhIAkpK\nSpg//73y4DF37uzt5vPIzs6mf/+BjBlzCAceOIaBAwfpAlMRqdOqOyLytZl1cPcVZQ1m9iBweVxb\nK+BJNI+ISLWtWLGCt956g0mTXuett97g22+3Xzeybdt2HHzwoRx88KEcdNAYWrX6XgSVioikRnWD\nSGXrcp8E/B+wYif7iUiopKSE996bw2uvvcykSW8wf/7213bn5uYyZMgwDj74UMaMOZTevfPIytL/\nWiJSP+3KbEWVfTJuvyCFSIZbt24tb731Jq+99jKvv/4KK1eu3G6fjh07cfDBh3HwwYcyatSBWqVW\nRDKGpk0USYHlyz/itdde5pVXXmb69Cnb3eHSsGFDhg0bwSGHBOGjWzfTqIeIZCQFEZEkKC4uZvbs\nmbzyykRKi/wtAAAbqUlEQVRee+1lCgp8u33atNmDww47gsMOO5LRo8fQvHmLCCoVEaldahJEKjvt\nolMxkrFWr17FpEmv8+qrLzNp0musXr16u3169+7D4YcfweGHH0W/fgPIzs6OoFIRkdqrJkHkNjMr\ninvcCLjRzMqmdm+SvLJEaqfPP/+Ml19+kZdeepFp097ZbtXaxo0bc+CBoznssCM57LAj2HPPjhFV\nKiJSN1Q3iEwG2ldomwq0Cb/i9xOpN2KxGPn5S5g4cQITJ75Y6V0uHTrsyWGHHcnhhx/ByJEH0bRp\n0wgqFRGpm6oVRNx9dIrrEKk1SkpKmDVrZhg+JrB8+Ufb7dOrVx5HHXUMRx55NHl5fXWhqYhIgnSx\nqgiwadMmJk9+k4kTX+SVV17a7hbb7Oxshg07IAwfx7DPPp2jKVREpJ5REJGMtX79el5//RVeeOE5\n3njjNTZu3LDN9saNGzN69CEcffSxHHbYkbRu3TqiSkVE6i8FEcko69ev49VXXw7Dx6ts2rRpm+2t\nWrXi8MOP4qijjuWgg8bQrFmziCoVEckMCiJS761bt5ZXXpnICy88x6RJr7F58+ZttnfosCfHHns8\nRx99HEOHDic3V/9biIikiz5xpV5au3YNL7/8EhMmPMebb76xXfjo2LETxx57AscffyIDBw7W/B4i\nIhFREJF6Y926tbz00gReeOFZ3nprElu2bNlm+1577V0ePgYMGKQ7XUREagEFEanTNm3axOuvv8oz\nz/yP1157ebtrPvbeex+OO+5EjjvuBPr3H6jwISJSyyiISJ1TXFzMlCmTeeaZ/zFhwvOsW7d2m+17\n792Z448/keOPP5G+ffsrfIiI1GIKIlInxGIx5syZxdNPP8lzzz3D11+v2GZ727btOPHEsYwde4pG\nPkRE6hAFEanVPvhgKU888RhPPfU/Pvlk+TbbWrbcjWOPPZ6xY09hxIhR5OTkRFOkiIgkTEFEap01\na1bz7LNP8/jjjzJnzqxttjVu3Jgjjjiak076PoccchiNGjWKqEoREUkGBRGpFYqLi3n77Un897//\nYeLEF7e53TYnJ4eDDhrD2LGncPTRx9K8eYsIKxURkWRSEJFI5ecv4b///Q9PPvk4K1YUbrOtR4+e\nnHbaOE4++VTatWsXUYUiIpJKCiKSdqtXr+Kpp57kv/99lHnz3ttm2/e+9z3Gjj2F008fp1VtRUQy\ngIKIpEUsFmP69Kk8/PADTJjw3DbzfeTm5nLooUdw+unjOPTQw2nYsGGElYqISDopiEhKrVz5Nf/+\n913cc889LF26dJtteXl9Of30MzjppFNo06ZNRBWKiEiUFEQk6UpLS3nnnbd55JEHeemlF9i6dWv5\nthYtWvL975/KD394Dnl5fSKsUkREagMFEUmawsKveOyxR3j00Yf4+OPl22wbMmQYP/zh2Rx33Ik0\na9YsmgJFRKTWURCRXRKLxZg69R3uu+9fTJw4gZKSkvJtrVq14rTTzuDii3/Knnt2pri4NMJKRUSk\nNqoVQcTMGgF3AmOBjcDN7n7LTo4ZCTzo7l3SUKJUsH79Op544nHuv/9fuOdvs23EiFH88Idnc8wx\nx9O8eVNatWrGqlUbIqpURERqs1oRRICbgAHAaKAz8JCZLXf3pyvb2czygCeBonQVKIGCAue+++7h\niSceZ/36deXtu+++Oz/4wZmcddY5dOnSNcIKRUSkLok8iJhZU+A84Ah3nw/MN7MbgYuB7YKImV0A\n/BX4ANgtnbVmquLiYl5++SXuv/9fvPPO29tsy8vry3nnnc+JJ55M06ZNI6pQRETqqsiDCNCXoI7p\ncW1TgCur2P8I4Exgd+Da1JaW2b799hsefvgB7r//Xr744vPy9gYNGnD88ScxfvyPGTRoiCYdExGR\nhNWGINIBWOnuxXFthUBjM2vt7t/E7+zuYwHM7Ow01phRli4t4J//vJMnn3yMoqLvzn7tuWdHzj57\nPOPGnU3btm0jrFBEROqL2hBEmgKbK7SVPU7J0qo5OdmpeNo6LRaL8eabk7j77jt4/fVXt9k2atSB\n/PjHP+HII48mN7dmb5myvlafp4/6PP3U5+mnPk+/VPV1bQgim9g+cJQ93piKF2zZskkqnrZOKioq\n4tFHH+XWW29l0aJF5e0NGzbkjDPO4JJLLqFfv367/Drq8/RTn6ef+jz91Od1X20IIp8Dbcws293L\nJppoDxS5++pUvODatUWUlGT2nBaFhYX8+9/3cP/99/LNN9+d/WrTpg3nnvsjxo//cfmKt7ty621O\nTjYtWzZRn6eR+jz91Ofppz5Pv7I+T7baEETmAVuBYcC0sG0UMCtVL1hSUpqxk2sVFDj/+MetPP30\nk2zZsqW8vXv3HlxwwUWcfPKpNG7cGCCpfZTJfR4V9Xn6qc/TT31e90UeRNy9yMweAu42s/FAJ+Ay\n4GwAM2sHrHH3TTt4GtmJ2bNnctttf+Pll1/cpv2QQw7jggsu4qCDxujuFxERSbvIg0joUoKZVScB\na4Cr3f25cNuXwDnAQ9GUVnfFYjEmTXqN22+/lWnTppS3N2zYkNNOO4MLLriIbt0swgpFRCTTZcVi\nsahrSLfYqlUb6vVQXnFxMc8//wy3334rixYtKG9v0aIl55xzHuef/1PatWufllpyc7PLp3ivz31e\nm6jP0099nn7q8/QL+zzpQ+e1ZUREkmDTpk089tgj3HHHbXzyyfLy9j32aMsFF1zEOeeMp2VLTUYr\nIiK1h4JIPVBUVMTDD9/P7bffSmHhV+XtnTvvy0UXXcJpp51RfgGqiIhIbaIgUodt2LCBBx+8jzvu\n+Dtff72ivL137z5ccsmlHHvsCeTk5ERYoYiIyI4piNRB69ev47777uWuu27bZg6QAQMGctllv+HQ\nQ4/QHTAiIlInKIjUIZs2beKBB+7l73+/eZsAMnjwUH71qysYPfpgBRAREalTFETqgK1bt/L4449y\n881/2WYV3AMOGMlll/2GkSMPVAAREZE6SUGkFistLeXZZ5/iL3/5Ix999GF5+8CBg7nqqmsZOfLA\nCKsTERHZdQoitdSkSa9z/fXXsHjxwvK2Hj16ceWV13D44UdqBEREROoFBZFaJj9/CddddxWTJr1e\n3ta5875cccXvOPHEk8nO1pLXIiJSfyiI1BIrVqzgxhtv4JFHHqC0NJglcI892vLrX1/JGWecSYMG\nDSKuUEREJPkURCK2detW7r77Dv72t7+yfv06ABo3bsyFF/6Miy/+Bc2bt4i4QhERkdRREInQzJnv\ncvnll7BkyeLytlNOOZ0rr7yGjh07RViZiIhIeiiIRGD16lX8/vfX8fDD95e3DR48lD/+8S/06zcg\nwspERETSS0EkzZ5//hmuuOJXrFz5NQC77bY711xzPePGnaULUUVEJOMoiKTJN998wxVXXMZzzz1d\n3jZ27Clcf/2faNu2bYSViYiIREdBJA1efPEFLr/8F+WjIJ067cXNN9/GmDGHRFyZiIhItBREUmjV\nqm+58spf89RTT5S3nXnmuVx33e9p0aJlhJWJiIjUDgoiKTJ16jv85CfnUVj4FQB77tmRW265nYMP\nPjTiykRERGoPXR2ZZKWlpdxyy42cfPJx5SHkjDPOZPLkGQohIiIiFWhEJIlWrlzJhRf+iLfemgQE\nd8TcdttdHHXUMRFXJiIiUjspiCTJjBnTOP/8c/nqqy8B6N9/AP/614Psvfc+EVcmIiJSe+nUzC4q\nLS3lttv+xkknHVMeQs4//6e88MKrCiEiIiI7oRGRXbB27Rouuuh8XnllIgAtWrTk1lvv4LjjToi4\nMhERkbpBQSRB7vmcffYP+PDDDwDo06cf//rXA+y7734RVyYiIlJ36NRMAl544VmOOGJMeQgZN+4s\nJkx4VSFERESkhjQiUgOxWIybbvozf/3rnwBo0KABN9zwV84661yysrIirk5ERKTuURCppi1btnDp\npT/jiSceA6Bdu/bcd9/DDB48NOLKRERE6i4FkWpYvXoV48efyZQpkwHo3bsPjz76BB067BlxZSIi\nInWbgshOFBZ+xcknH0dBgQNw6KGHc88999O8eYuIKxMREan7dLHqDhQWfsVJJx1THkLOOec8Hnro\ncYUQERGRJNGISBUKCwsZO/ZYli1bCsCvfnUFl1/+W12UKiIikkQKIpX49ttv+P73j2Pp0gIALrvs\nN/z611dGXJWIiEj9o1MzFWzYsIFx407FPR+AX/7yVwohIiIiKaIgEmfr1q386EdnMWfOLCBYM+aK\nK67W6RgREZEUURAJxWIxfvWrS3jjjdcAGDv2FK6//k8KISIiIimkIBJ64IF/89hjjwAwZswh3Hbb\nXWRnq3tERERSSb9pgdmzZ/K73/0GgP3378q99z5Iw4YNI65KRESk/sv4ILJ+/Tp+8pMfsXXrVpo2\nbcb99z9KixYtoy5LREQkI2R8ELnmmiv55JPlANx0062YdY+2IBERkQyS0UHkjTde5ZFHHgTghBPG\ncvLJp0ZckYiISGbJ2CBSXFzMNdcE84O0a9eeG2+8RXfIiIiIpFnGBpHHHnukfObUq666llatvhdx\nRSIiIpknI4PIhg0buPHGGwDo0aMXp5xyesQViYiIZKaMDCL/+c/DFBZ+BcDVV19HTk5OxBWJiIhk\npowLIrFYjAceuA+Avn37c8ghh0dckYiISObKuCAyY8YMlixZDMBZZ52rC1RFREQilHFB5K677gKg\nWbPmnHTSyRFXIyIiktkyLog88cQTAJxyymk0b94i4mpEREQyW8YFkc2bNwNwzjk/irgSERERybgg\nAjBgwEB69uwVdRkiIiIZLzfqAgDMrBFwJzAW2Ajc7O63VLFvf+AuIA9YCPzU3efW5PV+8INxu1aw\niIiIJEVtGRG5CRgAjAYuBK41s7EVdzKzpsCLwNvh/tOBF82sSXVf6LjjjuP00xVEREREaoPIg0gY\nLs4Dfu7u8939OeBG4OJKdj8d2Ojuv/HAL4B1wCnVfb3nn3+eZs2aJaN0ERER2UWRBxGgL8Epoulx\nbVOAoZXsOzTcFm8qMDw1pYmIiEgq1YYg0gFY6e7FcW2FQGMza13Jvl9UaCsEOqWwPhEREUmR2nCx\nalNgc4W2sseNqrlvxf12KCenNuSvzFDW1+rz9FGfp5/6PP3U5+mXqr6uDUFkE9sHibLHG6u5b8X9\ndiSrZctqX9sqSaI+Tz/1efqpz9NPfV731YYo+TnQxszia2kPFLn76kr2bV+hrT3wZQrrExERkRSp\nDUFkHrAVGBbXNgqYVcm+M4ADKrSNCNtFRESkjsmKxWJR14CZ3UUQKMYTXHj6AHC2uz9nZu2ANe6+\nycxaAEuBx4B7gJ8A3wf2d/eiSIoXERGRhNWGERGAS4E5wCTgduDqcD4RCE67nArg7uuAY4EDgdnA\nEOAohRAREZG6qVaMiIiIiEhmqi0jIiIiIpKBFEREREQkMgoiIiIiEhkFEREREYmMgoiIiIhEpjZM\n8Z4WZtYIuBMYSzAl/M3ufku0VdUPYd/OBi5y98lhW2fgXwQrIy8Hfunur8UdcyjwN2A/gpWXf+zu\nH6W38rrHzPYEbgPGELyPnwB+6+5b1OepYWZdgDsI5jr6BviHu98UbuuM+jylzOxFoNDdx4ePO6M+\nTzozOxF4GogBWeH3p9z91FT3eSaNiNwEDABGAxcC15rZ2EgrqgfCEPIY0LPCpmcJVkoeCDwCPGNm\nncJj9gKeAf4NDAJWhvvLzj0FNCb4pXg6cBzw+3Dbc6jPk8rMsoAXCVb57kcwieLvzOz0cBf1eQqF\n/XxUhWZ9tqRGT+B5gmVT2hOsdv+jcFtK3+cZEUTMrClwHvBzd58fTpZ2I3BxtJXVbWbWg2B6/X0r\ntB9MkIwv8MCfCVLy+HCXHwOz3P1Wd18CnAt0NrMD01d93WNmRjCJ3znunu/uU4FrgDPMbAzBfwf1\neXK1A94DLnT3D9z9ZeANYKT6PLXMrBXB5/TMuDZ9tqROD2Chu3/t7ivCr7Vhn6f0fZ4RQQToS3Aa\nanpc2xRgaDTl1BsHEXwoDycYyiszFJjr7pvi2qaE+5Vtn1y2IZwZd27cdqncV8CR7r6yQvtuBGs1\nqc+TzN2/cvcfuPsGADMbQbAW1luoz1PtJuAhYElcmz5bUqcnUFBJe8r7PFOuEekArHT34ri2QqCx\nmbV2928iqqtOc/e7y34O/lgv14FgGC9eIcE6QtXZLpVw9zVA/HnZLIJRvTdQn6ecmS0H9gImEJxL\nvxX1eUqEf4WPAvKAu+M26X2eOgYcaWZXATnAkwQjrinv80wJIk2BzRXayh43SnMtmaCq/m5Uze1S\nPX8F+gODCdZrUp+n1liCc+d3EVyYp/d5CoTXnd1NcDpsc4U/ctTnKWBmewNNgCLgFIJTMbeFbSnv\n80w5NbOJ7Tul7PHGNNeSCarq743V3C47YWZ/AX4OjHP3xajPU87d57r7SwSh7wIq/7BVn++66wiu\nOXi9km16n6eAu38CtHb389z9/fA6yl8C55OG93mmBJHPgTZmFv/vbQ8UufvqiGqqzz4n6N947QlW\nUq7OdtkBM7ud4ENinLuXXZ2uPk8BM2trZidUaF4MNCToO/V58p0GnGhm68xsHTAO+KGZrQU+Q32e\nEpX8LlxCcIfeV6S4zzMliMwDthJcXFZmFDArmnLqvRnAgHCItczIsL1s+8iyDeFdTf3jtksVzOxa\ngr9STnP3J+M2qc9TY1/gaTPrENc2CFhBcMHeQPV50h1EcG1I3/DreYLbR/sC76L3edKZ2eFmttLM\nGsc19ye4FfcdUvw+z4rFYonWXqeY2V0Ecy+MJ7iI5gHg7HAISnaRmZUCo919cjjyNB9YSDDHxfHA\nb4Fe7v6Zme1D8Ffl/xFc+Hct0NXdB0RTfd0Q3i79PnADweR88b5GfZ504Xt5OvAtwSmZfQnmS/gj\nwX+D94EFqM9TxszuB2LuPl6fLalhZs0J+m0ycD3QhWACs7+FXyl9n2fKiAgEHyJzgEnA7cDVCiFJ\nVZ5o3b0UOIFgeG42cAZwort/Fm7/mODCv/EEcwTsDpyU7oLroOMJ/p/9HcFV6l8QDH9+Efb5iajP\nkyruvbwBmAbcA9zq7v8Itx2P+jxt9NmSGu6+HjgC2IPgTMG/gLvd/eZ0vM8zZkREREREap9MGhER\nERGRWkZBRERERCKjICIiIiKRURARERGRyCiIiIiISGQURERERCQyCiIiIiISGQURERERiYyCiIiI\niEQmN+oCRKR6zGwccDHBgmAxgtUx73X3e8Lt9wFHAx3cfbspk83sKuAyoAPwT+Cs8HmygBJgFcE0\n5te4+/sp/wfVU2Z2AJDl7lOjrkWkLtCIiEgdYGbjgbvDr37AAOBB4DYzuzrc7d8Ea0UcVsXTnAk8\n6u6bCQLINIL1I9oTLOZ2AsEfJ1PNrG+K/imZYArBomEiUg0aERGpG35KMPrxYFzbUjPrBFwC/N7d\np5rZUmAc8Gr8wWY2DOgKnB7XvMXdv457/JmZnUiwfPftwIEp+HeIiGxDQUSkbigFDjCz3d19dVz7\nnwhGQsrcB1xlZo3dfVNc+9nAfHeft6MXcfdiM7sDuNfMOrr755XtZ2ZHECz33Rf4hmB05lp3LzWz\nxsBVBKt07gnkEwSlp8NjzyZYQfiv4X5tgJeAnwM3EqwivJrgFNH94TFvAvOAdgQjN98C/3D3v8TV\n1B34CzCC4LPtNeAyd/8k7jlmEIwanUwwIvwCcIG7bwj36QHcRBDC1hGs1n2ZuxdW5znMrJRgtOl+\nMxsdLl1/FvBrglGSb4Angd+4+5Yd/bcQyRQ6NSNSN9wIDAQ+N7MJZvZrMxvk7mvdfVncfg8BTQl+\nWQNgZg2BUwmW9q6OBQTXjVR6esbMhgMvAm8D/YEfAT8hCBcAjxOcBrqI4HqWZ4Enzez4uKfZB/g+\ncCTBEuInAAsJlhkfAEwE7jSzVnHH/JQggPQHrgSuMbPLw5r2BqYDRcBBBKen2gOTzax53HP8AvgS\nGEQwcnQi8MvwOToAkwEPazgGaAlMN7Mm1XkOgutvsghGqS4xszzgHuBqghGpc8O++VVlfSuSiTQi\nIlIHuPtT4UWQlwCHA0cBWWZWAIx392nhfl+Z2UsEvyD/Gx5+PNAY+E81X65sxGW3Krb/DJjh7r8N\nHxeY2flA23BU4njgGHd/Odz+f+E1J1cCz4dtOcDF7l4ALDGzecBmd/87gJndApwHdAPeDY/Jd/eL\n416zZ9gffyUIPeuAM919a/gc3wc+An5IcG0NwGJ3L7um5gMze5VgBAXgQuBTd7+07B9qZqcDXwOn\nEIS8HT6HuxeaGcBad19nZvsRjGZ97O6fEZz+OhxYW0XfimQcjYiI1BHuPtPdx7n7HgR/sV9F8Bf7\nS2bWJm7X+4AjzOx74eMzgWfcfU01X6osgKyuYnsewemJ+Nqecfd/8t0dPRXvGHk73Bbvg7ifN1R4\nXEQwstAoru2tCsdPAzqE/87ewOyyEBLWVEgwuhH/uvkVnmMN0DD8uT/Q28zWlX0BhWEN3av5HBW9\nHNY528w+MLO7gLYVRrFEMpqCiEgtZ2YdzewfZrZnWZu7z3f3PwGHEoSR+AtLJxCcwjg1DChHAffW\n4CUHEYSJqq4n2VpFOwThoTLZFY9z95IK+5TupK6Kr5sTfi+pweturmSfrLh9JwF9CE5LlX11I7hu\npDrPsQ133+zuhxKEnH8SnJ6ZYGY1+e8hUq8piIjUfpuAHxOcbqmobJSjsKwh/AX/MMEdMt8HPnH3\nt6rzQmaWDVwAvOnuX1ax22JgcIXjLjGz6cD7BL+UR1Y45sDwuF0xuMLjEcBH4UjP+8BgM2sQV1M7\ngl/8i6r5/AuBHsBn7v6hu39IMLfK39l+NKdazOxIM7s6DI43hqHkGra9e0kko+kaEZFazt2/MbO/\nAH8ws90I7rpYC/QiuED0jUomz/o3wQWULQhO1VSmYfjLGqABwVwilxHc3XHmDkr6KzDLzP6PIPB0\nC+v4m7vnm9kEggtNLwSWAj8AjiO4zmJXjDKza4FHCYLNhQQXjgLcRXDB7MNm9kegSVjnCr67VmZn\n7gTOBx41sz8QBKqbCE77LKxBneuBHuEpo63AteFpnmeB1sCxbH/qSiRjaUREpA5w92sILt4cBbxJ\nMKvqzcArBBeHVtzfCS7yzAMeqOJphwNfhF8fEtzt8g0w2N2rHEVw9/kEd4ocQ3CHzT8IQsgN4S6n\nAc8QnA6aH+431t2fqfY/OBALv8o8RzBi8T7wW+AX7v6vsKaPCe6WaUVw98xE4HNgpLtX68JQd18e\nPkcLgknJ3iS4VmWMu39Tg7pvJrig9z53fwMYH34tDOtyglubRQTIisW2mwlaRKRWCefv+Mjdx0dd\ni4gkl0ZEREREJDIKIiIiIhIZnZoRERGRyGhERERERCKjICIiIiKRURARERGRyCiIiIiISGQURERE\nRCQyCiIiIiISGQURERERiYyCiIiIiETm/wG1kvQzunrHmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a5d4e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(500)\n",
    "plt.plot(x, np.cumsum(svd.explained_variance_ratio_), color='black')\n",
    "plt.ylim(0, 0.5)\n",
    "\n",
    "plt.xlabel('SVD components')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_y = cleaned_data['user']\n",
    "c_X = c_transformed_X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "c_y = le.fit_transform(c_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_X_train, c_X_test, c_y_train, c_y_test = train_test_split(c_X, c_y, test_size=.3, random_state=50 )\n",
    "data_dict = {\n",
    "             'X_test' : c_X_test,\n",
    "             'X_train' : c_X_train,\n",
    "             'y_test' : c_y_test,\n",
    "             'y_train' : c_y_train} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tweets_df['user']\n",
    "X = transformed_X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=50 )\n",
    "data_dict = {\n",
    "             'X_test' : X_test,\n",
    "             'X_train' : X_train,\n",
    "             'y_test' : y_test,\n",
    "             'y_train' : y_train} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12483, 500), (29126, 500), (29126,), (12483,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['X_test'].shape, \\\n",
    "data_dict['X_train'].shape, \\\n",
    "data_dict['y_train'].shape, \\\n",
    "data_dict['y_test'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.00%\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(penalty='l2', C=1)\n",
    "log_reg.fit(X_train, y_train)\n",
    "accuracy = log_reg.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.21%\n"
     ]
    }
   ],
   "source": [
    "c_log_reg = LogisticRegression(penalty='l2', C=1)\n",
    "c_log_reg.fit(c_X_train, c_y_train)\n",
    "c_accuracy = c_log_reg.score(c_X_test, c_y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (c_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kdgulko/anaconda/lib/python2.7/site-packages/pandas/types/dtypes.py:127: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if string == 'category':\n"
     ]
    }
   ],
   "source": [
    "# pred_prob = log_reg.predict_proba(X_test[2050:2051])\n",
    "# pred_prob = pd.Series(pred_prob.flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# labels = twictionary.keys()\n",
    "# plt.pie(pred_prob, labels=labels, autopct='%1.1f%%',shadow=True, startangle=90)\n",
    "# plt.show()\n",
    "# actual = y_test[2000]\n",
    "# print(\"Probability: %.2f%%\" % (pred_prob.max() * 100.0))\n",
    "# print pred_prob.argmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X = tweets_df.text\n",
    "# # def clean_text(X):\n",
    "# #     all_words = [rb_words, gr_words, dt_words, bo_words, mm_words, ow_words, em_words, kk_words, kp_words, nc_worwords = X.replace('\\(', '').replace('\\)', '').replace('@', '').replace('https://.?', '')\n",
    "# X = re.sub(r\"http\\S+\", \"\", X)\n",
    "# X = re.sub(\"['\\''%'':''#'')''('';''\\n''/''.''!''*''-''+''$'',''?''~''&''@''``''-''=''--''|''<''>']\", \"\", X)\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# word_tokens = word_tokenize(X.lower())\n",
    "# filtered_text = [w for w in X if not w in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.27%\n"
     ]
    }
   ],
   "source": [
    "dec_tree = DecisionTreeClassifier(criterion='gini',max_depth=None, min_samples_split=3)\n",
    "dec_tree.fit(X_train, y_train)\n",
    "accuracy = dec_tree.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 51.19%\n"
     ]
    }
   ],
   "source": [
    "c_dec_tree = DecisionTreeClassifier(criterion='gini',max_depth=None, min_samples_split=3)\n",
    "c_dec_tree.fit(c_X_train, c_y_train)\n",
    "c_accuracy = c_dec_tree.score(c_X_test, c_y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (c_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.74%\n"
     ]
    }
   ],
   "source": [
    "rand_for = RandomForestClassifier(n_estimators=50, min_samples_split=3, criterion='gini')\n",
    "rand_for.fit(X_train, y_train)\n",
    "accuracy = rand_for.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 20.92%\n"
     ]
    }
   ],
   "source": [
    "c_rand_for = RandomForestClassifier(n_estimators=50, min_samples_split=3, criterion='gini')\n",
    "c_rand_for.fit(c_X_train, c_y_train)\n",
    "c_accuracy = rand_for.score(c_X_test, c_y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (c_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.14%\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='brute')\n",
    "knn.fit(X_train, y_train)\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.78%\n"
     ]
    }
   ],
   "source": [
    "c_knn = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='brute')\n",
    "c_knn.fit(c_X_train, c_y_train)\n",
    "c_accuracy = c_knn.score(c_X_test, c_y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (c_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.16%\n"
     ]
    }
   ],
   "source": [
    "ext_tree = ExtraTreesClassifier(n_estimators=50, criterion='entropy')\n",
    "ext_tree.fit(X_train, y_train)\n",
    "accuracy =  ext_tree.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.65%\n"
     ]
    }
   ],
   "source": [
    "c_ext_tree = ExtraTreesClassifier(n_estimators=50, criterion='entropy')\n",
    "c_ext_tree.fit(c_X_train, c_y_train)\n",
    "c_accuracy =  c_ext_tree.score(c_X_test, c_y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (c_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.25%\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "accuracy =  gnb.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 48.84%\n"
     ]
    }
   ],
   "source": [
    "c_gnb = GaussianNB()\n",
    "c_gnb.fit(c_X_train, c_y_train)\n",
    "c_accuracy =  c_gnb.score(c_X_test, c_y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (c_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-fe513e48fb59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mgbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kdgulko/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1028\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1029\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kdgulko/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1082\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kdgulko/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 787\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kdgulko/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1030\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kdgulko/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(max_depth=1, n_estimators=1000, warm_start=True)\n",
    "gbc.fit(X_train, y_train)\n",
    "accuracy =  gbc.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-77037d48e8e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mc_gbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mc_gbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mc_accuracy\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mc_gbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc_accuracy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kdgulko/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1028\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1029\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kdgulko/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1082\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kdgulko/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 787\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kdgulko/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1030\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kdgulko/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c_gbc = GradientBoostingClassifier(max_depth=1, n_estimators=1000, warm_start=True)\n",
    "c_gbc.fit(c_X_train, c_y_train)\n",
    "c_accuracy =  c_gbc.score(c_X_test, c_y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (c_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.44598767\n",
      "Iteration 2, loss = 2.39271307\n",
      "Iteration 3, loss = 2.32460934\n",
      "Iteration 4, loss = 2.21582953\n",
      "Iteration 5, loss = 2.06271237\n",
      "Iteration 6, loss = 1.88310639\n",
      "Iteration 7, loss = 1.70297243\n",
      "Iteration 8, loss = 1.53855335\n",
      "Iteration 9, loss = 1.39716897\n",
      "Iteration 10, loss = 1.28164570\n",
      "Iteration 11, loss = 1.18859987\n",
      "Iteration 12, loss = 1.11468709\n",
      "Iteration 13, loss = 1.05639372\n",
      "Iteration 14, loss = 1.00881387\n",
      "Iteration 15, loss = 0.97045764\n",
      "Iteration 16, loss = 0.93819692\n",
      "Iteration 17, loss = 0.91189466\n",
      "Iteration 18, loss = 0.88945850\n",
      "Iteration 19, loss = 0.87067964\n",
      "Iteration 20, loss = 0.85339020\n",
      "Iteration 21, loss = 0.83934119\n",
      "Iteration 22, loss = 0.82710766\n",
      "Iteration 23, loss = 0.81624520\n",
      "Iteration 24, loss = 0.80628581\n",
      "Iteration 25, loss = 0.79705152\n",
      "Iteration 26, loss = 0.78935761\n",
      "Iteration 27, loss = 0.78165405\n",
      "Iteration 28, loss = 0.77549137\n",
      "Iteration 29, loss = 0.76928791\n",
      "Iteration 30, loss = 0.76397480\n",
      "Iteration 31, loss = 0.75939521\n",
      "Iteration 32, loss = 0.75408792\n",
      "Iteration 33, loss = 0.75014006\n",
      "Iteration 34, loss = 0.74652428\n",
      "Iteration 35, loss = 0.74191543\n",
      "Iteration 36, loss = 0.73868946\n",
      "Iteration 37, loss = 0.73550439\n",
      "Iteration 38, loss = 0.73271599\n",
      "Iteration 39, loss = 0.72988482\n",
      "Iteration 40, loss = 0.72724164\n",
      "Iteration 41, loss = 0.72439954\n",
      "Iteration 42, loss = 0.72207343\n",
      "Iteration 43, loss = 0.71976698\n",
      "Iteration 44, loss = 0.71788530\n",
      "Iteration 45, loss = 0.71545903\n",
      "Iteration 46, loss = 0.71357148\n",
      "Iteration 47, loss = 0.71190083\n",
      "Iteration 48, loss = 0.71028774\n",
      "Iteration 49, loss = 0.70827426\n",
      "Iteration 50, loss = 0.70683773\n",
      "Iteration 51, loss = 0.70471206\n",
      "Iteration 52, loss = 0.70361399\n",
      "Iteration 53, loss = 0.70167055\n",
      "Iteration 54, loss = 0.70093403\n",
      "Iteration 55, loss = 0.69941909\n",
      "Iteration 56, loss = 0.69820914\n",
      "Iteration 57, loss = 0.69673975\n",
      "Iteration 58, loss = 0.69520732\n",
      "Iteration 59, loss = 0.69395312\n",
      "Iteration 60, loss = 0.69309206\n",
      "Iteration 61, loss = 0.69190242\n",
      "Iteration 62, loss = 0.69090006\n",
      "Iteration 63, loss = 0.69012456\n",
      "Iteration 64, loss = 0.68866990\n",
      "Iteration 65, loss = 0.68856391\n",
      "Iteration 66, loss = 0.68727957\n",
      "Iteration 67, loss = 0.68658012\n",
      "Iteration 68, loss = 0.68545967\n",
      "Iteration 69, loss = 0.68434954\n",
      "Iteration 70, loss = 0.68342571\n",
      "Iteration 71, loss = 0.68312367\n",
      "Iteration 72, loss = 0.68222986\n",
      "Iteration 73, loss = 0.68084282\n",
      "Iteration 74, loss = 0.68028408\n",
      "Iteration 75, loss = 0.68031458\n",
      "Iteration 76, loss = 0.67855227\n",
      "Iteration 77, loss = 0.67856749\n",
      "Iteration 78, loss = 0.67776993\n",
      "Iteration 79, loss = 0.67699395\n",
      "Iteration 80, loss = 0.67668173\n",
      "Iteration 81, loss = 0.67546370\n",
      "Iteration 82, loss = 0.67522246\n",
      "Iteration 83, loss = 0.67411398\n",
      "Iteration 84, loss = 0.67371047\n",
      "Iteration 85, loss = 0.67329726\n",
      "Iteration 86, loss = 0.67247592\n",
      "Iteration 87, loss = 0.67205265\n",
      "Iteration 88, loss = 0.67151024\n",
      "Iteration 89, loss = 0.67095926\n",
      "Iteration 90, loss = 0.66983215\n",
      "Iteration 91, loss = 0.67038478\n",
      "Iteration 92, loss = 0.66932847\n",
      "Iteration 93, loss = 0.66889559\n",
      "Iteration 94, loss = 0.66798014\n",
      "Iteration 95, loss = 0.66771246\n",
      "Iteration 96, loss = 0.66708321\n",
      "Iteration 97, loss = 0.66628452\n",
      "Iteration 98, loss = 0.66612142\n",
      "Iteration 99, loss = 0.66568489\n",
      "Iteration 100, loss = 0.66510439\n",
      "Iteration 101, loss = 0.66458479\n",
      "Iteration 102, loss = 0.66364939\n",
      "Iteration 103, loss = 0.66364324\n",
      "Iteration 104, loss = 0.66358075\n",
      "Iteration 105, loss = 0.66251889\n",
      "Iteration 106, loss = 0.66269480\n",
      "Iteration 107, loss = 0.66188851\n",
      "Iteration 108, loss = 0.66175999\n",
      "Iteration 109, loss = 0.66093486\n",
      "Iteration 110, loss = 0.66095052\n",
      "Iteration 111, loss = 0.66000682\n",
      "Iteration 112, loss = 0.65956361\n",
      "Iteration 113, loss = 0.65963152\n",
      "Iteration 114, loss = 0.65883763\n",
      "Iteration 115, loss = 0.65858096\n",
      "Iteration 116, loss = 0.65870986\n",
      "Iteration 117, loss = 0.65810463\n",
      "Iteration 118, loss = 0.65796742\n",
      "Iteration 119, loss = 0.65698458\n",
      "Iteration 120, loss = 0.65705404\n",
      "Iteration 121, loss = 0.65669162\n",
      "Iteration 122, loss = 0.65639804\n",
      "Iteration 123, loss = 0.65615157\n",
      "Iteration 124, loss = 0.65578507\n",
      "Iteration 125, loss = 0.65502696\n",
      "Iteration 126, loss = 0.65509600\n",
      "Iteration 127, loss = 0.65485551\n",
      "Iteration 128, loss = 0.65432704\n",
      "Iteration 129, loss = 0.65392876\n",
      "Iteration 130, loss = 0.65354936\n",
      "Iteration 131, loss = 0.65336477\n",
      "Iteration 132, loss = 0.65294412\n",
      "Iteration 133, loss = 0.65248413\n",
      "Iteration 134, loss = 0.65229798\n",
      "Iteration 135, loss = 0.65222144\n",
      "Iteration 136, loss = 0.65136908\n",
      "Iteration 137, loss = 0.65108725\n",
      "Iteration 138, loss = 0.65060457\n",
      "Iteration 139, loss = 0.65085053\n",
      "Iteration 140, loss = 0.65070186\n",
      "Iteration 141, loss = 0.65039337\n",
      "Iteration 142, loss = 0.64975512\n",
      "Iteration 143, loss = 0.64941418\n",
      "Iteration 144, loss = 0.64956219\n",
      "Iteration 145, loss = 0.64902674\n",
      "Iteration 146, loss = 0.64877480\n",
      "Iteration 147, loss = 0.64873391\n",
      "Iteration 148, loss = 0.64798109\n",
      "Iteration 149, loss = 0.64799103\n",
      "Iteration 150, loss = 0.64779078\n",
      "Iteration 151, loss = 0.64737574\n",
      "Iteration 152, loss = 0.64704919\n",
      "Iteration 153, loss = 0.64682557\n",
      "Iteration 154, loss = 0.64622056\n",
      "Iteration 155, loss = 0.64603162\n",
      "Iteration 156, loss = 0.64613700\n",
      "Iteration 157, loss = 0.64559540\n",
      "Iteration 158, loss = 0.64529942\n",
      "Iteration 159, loss = 0.64476560\n",
      "Iteration 160, loss = 0.64537849\n",
      "Iteration 161, loss = 0.64474051\n",
      "Iteration 162, loss = 0.64435479\n",
      "Iteration 163, loss = 0.64410891\n",
      "Iteration 164, loss = 0.64432708\n",
      "Iteration 165, loss = 0.64327007\n",
      "Iteration 166, loss = 0.64363400\n",
      "Iteration 167, loss = 0.64314424\n",
      "Iteration 168, loss = 0.64269781\n",
      "Iteration 169, loss = 0.64265983\n",
      "Iteration 170, loss = 0.64259427\n",
      "Iteration 171, loss = 0.64270386\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Accuracy: 75.16%\n"
     ]
    }
   ],
   "source": [
    "mlpc = nn.MLPClassifier(verbose=2, max_iter=2000, activation = 'logistic', hidden_layer_sizes= (100,))                    \n",
    "mlpc.fit(X_train, y_train)\n",
    "\n",
    "pred= mlpc.predict(X_test)\n",
    "mlpc_results = zip(pred,y_test)\n",
    "results = []\n",
    "for m in mlpc_results:\n",
    "    if m[0] == m[1]:\n",
    "        results.append(int(1))\n",
    "    else:\n",
    "        results.append(int(0))\n",
    "accuracy = float(sum(results))/len(results)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.43642549\n",
      "Iteration 2, loss = 2.36710594\n",
      "Iteration 3, loss = 2.26539567\n",
      "Iteration 4, loss = 2.10876468\n",
      "Iteration 5, loss = 1.90961373\n",
      "Iteration 6, loss = 1.70568232\n",
      "Iteration 7, loss = 1.52385751\n",
      "Iteration 8, loss = 1.37599246\n",
      "Iteration 9, loss = 1.26217465\n",
      "Iteration 10, loss = 1.17586483\n",
      "Iteration 11, loss = 1.11023032\n",
      "Iteration 12, loss = 1.05998404\n",
      "Iteration 13, loss = 1.02052608\n",
      "Iteration 14, loss = 0.98874189\n",
      "Iteration 15, loss = 0.96405072\n",
      "Iteration 16, loss = 0.94294776\n",
      "Iteration 17, loss = 0.92584237\n",
      "Iteration 18, loss = 0.91085920\n",
      "Iteration 19, loss = 0.89815412\n",
      "Iteration 20, loss = 0.88753338\n",
      "Iteration 21, loss = 0.87783800\n",
      "Iteration 22, loss = 0.86930878\n",
      "Iteration 23, loss = 0.86182588\n",
      "Iteration 24, loss = 0.85470617\n",
      "Iteration 25, loss = 0.84932451\n",
      "Iteration 26, loss = 0.84339135\n",
      "Iteration 27, loss = 0.83829191\n",
      "Iteration 28, loss = 0.83368231\n",
      "Iteration 29, loss = 0.82895102\n",
      "Iteration 30, loss = 0.82543079\n",
      "Iteration 31, loss = 0.82167223\n",
      "Iteration 32, loss = 0.81841340\n",
      "Iteration 33, loss = 0.81511568\n",
      "Iteration 34, loss = 0.81199086\n",
      "Iteration 35, loss = 0.80971584\n",
      "Iteration 36, loss = 0.80669169\n",
      "Iteration 37, loss = 0.80382847\n",
      "Iteration 38, loss = 0.80163778\n",
      "Iteration 39, loss = 0.79949166\n",
      "Iteration 40, loss = 0.79781554\n",
      "Iteration 41, loss = 0.79545020\n",
      "Iteration 42, loss = 0.79397135\n",
      "Iteration 43, loss = 0.79169915\n",
      "Iteration 44, loss = 0.79063713\n",
      "Iteration 45, loss = 0.78815597\n",
      "Iteration 46, loss = 0.78693217\n",
      "Iteration 47, loss = 0.78545677\n",
      "Iteration 48, loss = 0.78411737\n",
      "Iteration 49, loss = 0.78266897\n",
      "Iteration 50, loss = 0.78135513\n",
      "Iteration 51, loss = 0.78022128\n",
      "Iteration 52, loss = 0.77831555\n",
      "Iteration 53, loss = 0.77753531\n",
      "Iteration 54, loss = 0.77601868\n",
      "Iteration 55, loss = 0.77527535\n",
      "Iteration 56, loss = 0.77386915\n",
      "Iteration 57, loss = 0.77331201\n",
      "Iteration 58, loss = 0.77205003\n",
      "Iteration 59, loss = 0.77087039\n",
      "Iteration 60, loss = 0.76964315\n",
      "Iteration 61, loss = 0.76887740\n",
      "Iteration 62, loss = 0.76794639\n",
      "Iteration 63, loss = 0.76693370\n",
      "Iteration 64, loss = 0.76655909\n",
      "Iteration 65, loss = 0.76560722\n",
      "Iteration 66, loss = 0.76479252\n",
      "Iteration 67, loss = 0.76349369\n",
      "Iteration 68, loss = 0.76295169\n",
      "Iteration 69, loss = 0.76225366\n",
      "Iteration 70, loss = 0.76146322\n",
      "Iteration 71, loss = 0.76096301\n",
      "Iteration 72, loss = 0.75997973\n",
      "Iteration 73, loss = 0.75946746\n",
      "Iteration 74, loss = 0.75855858\n",
      "Iteration 75, loss = 0.75807664\n",
      "Iteration 76, loss = 0.75710173\n",
      "Iteration 77, loss = 0.75635626\n",
      "Iteration 78, loss = 0.75581734\n",
      "Iteration 79, loss = 0.75544936\n",
      "Iteration 80, loss = 0.75462806\n",
      "Iteration 81, loss = 0.75397367\n",
      "Iteration 82, loss = 0.75335925\n",
      "Iteration 83, loss = 0.75328807\n",
      "Iteration 84, loss = 0.75250436\n",
      "Iteration 85, loss = 0.75137744\n",
      "Iteration 86, loss = 0.75129243\n",
      "Iteration 87, loss = 0.75081163\n",
      "Iteration 88, loss = 0.75011631\n",
      "Iteration 89, loss = 0.75013470\n",
      "Iteration 90, loss = 0.74886222\n",
      "Iteration 91, loss = 0.74897785\n",
      "Iteration 92, loss = 0.74826609\n",
      "Iteration 93, loss = 0.74746197\n",
      "Iteration 94, loss = 0.74704004\n",
      "Iteration 95, loss = 0.74657464\n",
      "Iteration 96, loss = 0.74670641\n",
      "Iteration 97, loss = 0.74586296\n",
      "Iteration 98, loss = 0.74540117\n",
      "Iteration 99, loss = 0.74498183\n",
      "Iteration 100, loss = 0.74441913\n",
      "Iteration 101, loss = 0.74432991\n",
      "Iteration 102, loss = 0.74344286\n",
      "Iteration 103, loss = 0.74292027\n",
      "Iteration 104, loss = 0.74244260\n",
      "Iteration 105, loss = 0.74257275\n",
      "Iteration 106, loss = 0.74183302\n",
      "Iteration 107, loss = 0.74190585\n",
      "Iteration 108, loss = 0.74100004\n",
      "Iteration 109, loss = 0.74062241\n",
      "Iteration 110, loss = 0.74028719\n",
      "Iteration 111, loss = 0.73966569\n",
      "Iteration 112, loss = 0.73947358\n",
      "Iteration 113, loss = 0.73887272\n",
      "Iteration 114, loss = 0.73876471\n",
      "Iteration 115, loss = 0.73898820\n",
      "Iteration 116, loss = 0.73807655\n",
      "Iteration 117, loss = 0.73766708\n",
      "Iteration 118, loss = 0.73715936\n",
      "Iteration 119, loss = 0.73678672\n",
      "Iteration 120, loss = 0.73661964\n",
      "Iteration 121, loss = 0.73638649\n",
      "Iteration 122, loss = 0.73604154\n",
      "Iteration 123, loss = 0.73539573\n",
      "Iteration 124, loss = 0.73584572\n",
      "Iteration 125, loss = 0.73452754\n",
      "Iteration 126, loss = 0.73427483\n",
      "Iteration 127, loss = 0.73385929\n",
      "Iteration 128, loss = 0.73363670\n",
      "Iteration 129, loss = 0.73325192\n",
      "Iteration 130, loss = 0.73315478\n",
      "Iteration 131, loss = 0.73287134\n",
      "Iteration 132, loss = 0.73232205\n",
      "Iteration 133, loss = 0.73249282\n",
      "Iteration 134, loss = 0.73210957\n",
      "Iteration 135, loss = 0.73200774\n",
      "Iteration 136, loss = 0.73119591\n",
      "Iteration 137, loss = 0.73104965\n",
      "Iteration 138, loss = 0.73032784\n",
      "Iteration 139, loss = 0.73014293\n",
      "Iteration 140, loss = 0.73011552\n",
      "Iteration 141, loss = 0.72934790\n",
      "Iteration 142, loss = 0.72981930\n",
      "Iteration 143, loss = 0.72875134\n",
      "Iteration 144, loss = 0.72886654\n",
      "Iteration 145, loss = 0.72857075\n",
      "Iteration 146, loss = 0.72853827\n",
      "Iteration 147, loss = 0.72787174\n",
      "Iteration 148, loss = 0.72757663\n",
      "Iteration 149, loss = 0.72702804\n",
      "Iteration 150, loss = 0.72692428\n",
      "Iteration 151, loss = 0.72730437\n",
      "Iteration 152, loss = 0.72649299\n",
      "Iteration 153, loss = 0.72621298\n",
      "Iteration 154, loss = 0.72595217\n",
      "Iteration 155, loss = 0.72537392\n",
      "Iteration 156, loss = 0.72520008\n",
      "Iteration 157, loss = 0.72509770\n",
      "Iteration 158, loss = 0.72468355\n",
      "Iteration 159, loss = 0.72492098\n",
      "Iteration 160, loss = 0.72467263\n",
      "Iteration 161, loss = 0.72388926\n",
      "Iteration 162, loss = 0.72398547\n",
      "Iteration 163, loss = 0.72347488\n",
      "Iteration 164, loss = 0.72285313\n",
      "Iteration 165, loss = 0.72264132\n",
      "Iteration 166, loss = 0.72227116\n",
      "Iteration 167, loss = 0.72237765\n",
      "Iteration 168, loss = 0.72232403\n",
      "Iteration 169, loss = 0.72140333\n",
      "Iteration 170, loss = 0.72147357\n",
      "Iteration 171, loss = 0.72148454\n",
      "Iteration 172, loss = 0.72105563\n",
      "Iteration 173, loss = 0.72046919\n",
      "Iteration 174, loss = 0.72070844\n",
      "Iteration 175, loss = 0.72018521\n",
      "Iteration 176, loss = 0.72049973\n",
      "Iteration 177, loss = 0.71992831\n",
      "Iteration 178, loss = 0.71952617\n",
      "Iteration 179, loss = 0.71912376\n",
      "Iteration 180, loss = 0.71904147\n",
      "Iteration 181, loss = 0.71878432\n",
      "Iteration 182, loss = 0.71820497\n",
      "Iteration 183, loss = 0.71818519\n",
      "Iteration 184, loss = 0.71752221\n",
      "Iteration 185, loss = 0.71718699\n",
      "Iteration 186, loss = 0.71743382\n",
      "Iteration 187, loss = 0.71700618\n",
      "Iteration 188, loss = 0.71689194\n",
      "Iteration 189, loss = 0.71646639\n",
      "Iteration 190, loss = 0.71663289\n",
      "Iteration 191, loss = 0.71585438\n",
      "Iteration 192, loss = 0.71571441\n",
      "Iteration 193, loss = 0.71550977\n",
      "Iteration 194, loss = 0.71547683\n",
      "Iteration 195, loss = 0.71502869\n",
      "Iteration 196, loss = 0.71495892\n",
      "Iteration 197, loss = 0.71509494\n",
      "Iteration 198, loss = 0.71474404\n",
      "Iteration 199, loss = 0.71440990\n",
      "Iteration 200, loss = 0.71356192\n",
      "Iteration 201, loss = 0.71365502\n",
      "Iteration 202, loss = 0.71360905\n",
      "Iteration 203, loss = 0.71300650\n",
      "Iteration 204, loss = 0.71274170\n",
      "Iteration 205, loss = 0.71269805\n",
      "Iteration 206, loss = 0.71230829\n",
      "Iteration 207, loss = 0.71230503\n",
      "Iteration 208, loss = 0.71185990\n",
      "Iteration 209, loss = 0.71193967\n",
      "Iteration 210, loss = 0.71168298\n",
      "Iteration 211, loss = 0.71134885\n",
      "Iteration 212, loss = 0.71117840\n",
      "Iteration 213, loss = 0.71057549\n",
      "Iteration 214, loss = 0.71027129\n",
      "Iteration 215, loss = 0.71047274\n",
      "Iteration 216, loss = 0.71001642\n",
      "Iteration 217, loss = 0.71026822\n",
      "Iteration 218, loss = 0.70953914\n",
      "Iteration 219, loss = 0.70964445\n",
      "Iteration 220, loss = 0.70931303\n",
      "Iteration 221, loss = 0.70893415\n",
      "Iteration 222, loss = 0.70841574\n",
      "Iteration 223, loss = 0.70834213\n",
      "Iteration 224, loss = 0.70809887\n",
      "Iteration 225, loss = 0.70805013\n",
      "Iteration 226, loss = 0.70787262\n",
      "Iteration 227, loss = 0.70771789\n",
      "Iteration 228, loss = 0.70731625\n",
      "Iteration 229, loss = 0.70676942\n",
      "Iteration 230, loss = 0.70735857\n",
      "Iteration 231, loss = 0.70630653\n",
      "Iteration 232, loss = 0.70625809\n",
      "Iteration 233, loss = 0.70587663\n",
      "Iteration 234, loss = 0.70602993\n",
      "Iteration 235, loss = 0.70606468\n",
      "Iteration 236, loss = 0.70519604\n",
      "Iteration 237, loss = 0.70480619\n",
      "Iteration 238, loss = 0.70501298\n",
      "Iteration 239, loss = 0.70481010\n",
      "Iteration 240, loss = 0.70475215\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Accuracy: 72.17%\n"
     ]
    }
   ],
   "source": [
    "mlpc = nn.MLPClassifier(verbose=2, max_iter=2000, activation = 'logistic', hidden_layer_sizes= (100,))                    \n",
    "mlpc.fit(c_X_train, c_y_train)\n",
    "\n",
    "c_pred= mlpc.predict(c_X_test)\n",
    "c_mlpc_results = zip(c_pred,c_y_test)\n",
    "results = []\n",
    "for m in c_mlpc_results:\n",
    "    if m[0] == m[1]:\n",
    "        results.append(int(1))\n",
    "    else:\n",
    "        results.append(int(0))\n",
    "c_accuracy = float(sum(results))/len(results)\n",
    "print(\"Accuracy: %.2f%%\" % (c_accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 2,\n",
    "    'learning_rate': 1.0,\n",
    "    'silent': 1.0,\n",
    "    'n_estimators': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst = XGBClassifier(**params).fit(c_X_train, c_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  5, 11, ...,  7, 10,  9])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_preds = bst.predict(c_X_test)\n",
    "c_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted correctly: 6769/12483\n",
      "Error: 0.4577\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for i in range(len(c_preds)):\n",
    "    if (y_test[i] == c_preds[i]):\n",
    "        correct += 1\n",
    "        \n",
    "acc = accuracy_score(c_y_test, c_preds)\n",
    "\n",
    "print('Predicted correctly: {0}/{1}'.format(correct, len(c_preds)))\n",
    "print('Error: {0:.4f}'.format(1-acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 342\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "k-fold cross validation requires at least one train / test split by setting n_folds=2 or more, got n_folds=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-f90a081b6ebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/kdgulko/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, y, n_folds, shuffle, random_state)\u001b[0m\n\u001b[1;32m    535\u001b[0m                  random_state=None):\n\u001b[1;32m    536\u001b[0m         super(StratifiedKFold, self).__init__(\n\u001b[0;32m--> 537\u001b[0;31m             len(y), n_folds, shuffle, random_state)\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kdgulko/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n, n_folds, shuffle, random_state)\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;34m\"k-fold cross validation requires at least one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;34m\" train / test split by setting n_folds=2 or more,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                 \" got n_folds={0}.\".format(n_folds))\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_folds\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: k-fold cross validation requires at least one train / test split by setting n_folds=2 or more, got n_folds=1."
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(y, n_folds=1, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    'max_depth': [1, 2, 3],\n",
    "    'n_estimators': [5, 10, 25, 50],\n",
    "    'learning_rate': np.linspace(1e-16, 1, 3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_fixed = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'silent': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst_grid = GridSearchCV(\n",
    "    estimator=XGBClassifier(params_fixed, seed=seed),\n",
    "    param_grid=params_grid,\n",
    "    cv=cv,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bst_grid.fit(X, y)\n",
    "bst_grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best accuracy obtained: {0}\".format(bst_grid.best_score_))\n",
    "print(\"Parameters:\")\n",
    "for key, value in bst_grid.best_params_.items():\n",
    "    print(\"\\t{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_dist_grid = {\n",
    "    'max_depth': [1, 2, 3, 4],\n",
    "    'gamma': [0, 0.5, 1],\n",
    "    'n_estimators': randint(1, 1001), # uniform discrete random distribution\n",
    "    'learning_rate': uniform(), # gaussian distribution\n",
    "    'subsample': uniform(), # gaussian distribution\n",
    "    'colsample_bytree': uniform() # gaussian distribution\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs_grid = RandomizedSearchCV(\n",
    "    estimator=XGBClassifier(params_fixed, seed=seed),\n",
    "    param_distributions=params_dist_grid,\n",
    "    n_iter=10,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs_grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
